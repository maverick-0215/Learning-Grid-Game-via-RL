<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>15-Puzzle Reinforcement Learning Simulator</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Times New Roman', Times, serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
            line-height: 1.6;
        }

        /* Top Navigation Bar */
        .navbar {
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: white;
            padding: 0;
            box-shadow: 0 4px 20px rgba(0,0,0,0.15);
            position: sticky;
            top: 0;
            z-index: 1000;
            border-bottom: 2px solid #0f3460;
        }

        .navbar-content {
            max-width: 1400px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0 30px;
        }

        .navbar-title {
            padding: 20px 0;
        }

        .navbar h1 {
            color: white;
            font-size: 1.9em;
            font-weight: 600;
            letter-spacing: 1px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }

        .navbar-links {
            display: flex;
            gap: 0;
        }

        .navbar-links a {
            color: white;
            text-decoration: none;
            padding: 25px 24px;
            font-size: 0.98em;
            font-weight: 500;
            transition: all 0.3s ease;
            border-bottom: 3px solid transparent;
            letter-spacing: 0.3px;
        }

        .navbar-links a:hover {
            background: rgba(255, 255, 255, 0.1);
            border-bottom-color: #4a90e2;
            transform: translateY(-2px);
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            padding: 50px;
            min-height: calc(100vh - 200px);
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
        }

        h1 {
            text-align: center;
            color: #1a1a2e;
            margin-bottom: 10px;
            font-size: 2em;
            font-weight: 600;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1em;
            font-style: italic;
        }

        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 35px;
            margin-top: 40px;
        }

        .panel {
            background: #ffffff;
            border: 1px solid #ddd;
            border-radius: 6px;
            padding: 30px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }

        .panel h2 {
            color: #1a1a2e;
            margin-bottom: 25px;
            font-size: 1.4em;
            border-bottom: 2px solid #1a1a2e;
            padding-bottom: 12px;
            font-weight: 600;
        }

        .control-group {
            margin-bottom: 25px;
        }

        .control-group label {
            display: block;
            font-weight: 600;
            margin-bottom: 10px;
            color: #444;
            font-size: 1.05em;
            letter-spacing: 0.3px;
        }

        input[type="number"] {
            width: 100%;
            padding: 12px 15px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 15px;
            transition: all 0.3s ease;
            font-family: 'Times New Roman', Times, serif;
            background: white;
        }

        input[type="number"]:focus {
            outline: none;
            border-color: #1a1a2e;
        }

        .grid-container {
            display: inline-block;
            margin: 20px auto;
            padding: 20px;
            background: #ffffff;
            border: 1px solid #ddd;
            border-radius: 6px;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(4, 70px);
            gap: 4px;
            background: #2c3e50;
            border: 2px solid #2c3e50;
            margin: 0 auto;
            border-radius: 4px;
            padding: 4px;
        }

        .tile {
            width: 70px;
            height: 70px;
            background: linear-gradient(135deg, #3498db, #2980b9);
            border-radius: 4px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 28px;
            font-weight: bold;
            color: white;
            cursor: pointer;
            transition: all 0.2s ease;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }

        .tile:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        }

        .tile.empty {
            background: #ecf0f1;
            cursor: default;
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.1);
        }

        .tile.empty:hover {
            transform: none;
        }

        .tile.moving {
            animation: slideMove 0.2s ease;
        }

        @keyframes slideMove {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .algorithm-selector {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        .algorithm-option {
            display: flex;
            align-items: center;
            padding: 15px;
            background: white;
            border: 1px solid #ddd;
            border-radius: 4px;
            cursor: pointer;
            transition: border-color 0.2s ease;
        }

        .algorithm-option:hover {
            border-color: #1a1a2e;
        }

        .algorithm-option input[type="checkbox"] {
            width: 18px;
            height: 18px;
            cursor: pointer;
            margin-right: 12px;
        }

        .algorithm-option label {
            cursor: pointer;
            font-weight: 400;
            color: #333;
            margin: 0;
            font-size: 0.95em;
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-top: 25px;
        }

        button {
            flex: 1;
            padding: 14px 28px;
            font-size: 15px;
            font-weight: 600;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.2s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            font-family: 'Times New Roman', Times, serif;
        }

        button.primary {
            background: #1a1a2e;
            color: white;
        }

        button.primary:hover {
            background: #0f1419;
        }

        button.secondary {
            background: #e0e0e0;
            color: #333;
        }

        button.secondary:hover {
            background: #d0d0d0;
        }

        button.simulate-btn {
            background: #555;
            color: white;
        }

        button.simulate-btn:hover {
            background: #333;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .results-panel {
            grid-column: 1 / -1;
        }

        #resultsChart {
            width: 100%;
            height: 400px;
            border: 1px solid #ddd;
            border-radius: 3px;
            margin-top: 20px;
            background: white;
        }

        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .stat-card {
            background: #ffffff;
            padding: 25px;
            border: 1px solid #ddd;
            border-radius: 6px;
            border-left: 4px solid #1a1a2e;
        }

        .stat-card h3 {
            color: #1a1a2e;
            font-size: 0.9em;
            text-transform: uppercase;
            margin-bottom: 12px;
            font-weight: 600;
        }

        .stat-card .value {
            font-size: 2.2em;
            font-weight: 700;
            color: #1a1a2e;
        }

        .loading {
            text-align: center;
            padding: 20px;
            font-size: 1.1em;
            color: #1a1a2e;
            font-style: italic;
        }

        .hyperparameters {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-top: 15px;
        }

        .hyperparam-input {
            display: flex;
            flex-direction: column;
        }

        .hyperparam-input label {
            font-size: 0.9em;
            font-weight: 500;
            margin-bottom: 5px;
            color: #555;
        }

        .hyperparam-input input {
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 3px;
            font-size: 14px;
            font-family: 'Times New Roman', Times, serif;
        }

        /* Modal Styles */
        .modal {
            display: none;
            position: fixed;
            z-index: 2000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.5);
            overflow: auto;
        }

        .modal-content {
            background: #ffffff;
            margin: 5% auto;
            padding: 0;
            border: 1px solid #ddd;
            width: 80%;
            max-width: 900px;
            border-radius: 6px;
            max-height: 80vh;
            overflow-y: auto;
        }

        .modal-header {
            background: #1a1a2e;
            color: white;
            padding: 25px 35px;
            border-radius: 6px 6px 0 0;
        }

        .modal-header h2 {
            margin: 0;
            font-size: 1.6em;
            color: white;
            border: none;
        }

        .modal-body {
            padding: 35px;
            line-height: 1.7;
        }

        .modal-body h3 {
            color: #1a1a2e;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.25em;
            border-bottom: 2px solid #ddd;
            padding-bottom: 8px;
            font-weight: 600;
        }

        .modal-body p, .modal-body li {
            line-height: 1.9;
            color: #444;
            margin-bottom: 10px;
        }

        .modal-body ul {
            margin-left: 30px;
            margin-top: 12px;
        }

        .close {
            color: white;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
            line-height: 20px;
            transition: opacity 0.2s ease;
        }

        .close:hover {
            opacity: 0.7;
        }

        .equation {
            background: #f5f5f5;
            padding: 18px 20px;
            margin: 18px 0;
            border-left: 4px solid #1a1a2e;
            font-family: 'Courier New', monospace;
            font-size: 1.05em;
            overflow-x: auto;
            border-radius: 4px;
        }

        .algorithm-description {
            margin-bottom: 30px;
            padding: 20px;
            background: #f9f9f9;
            border-radius: 6px;
            border: 1px solid #ddd;
        }

        .footer {
            background: #1a1a2e;
            color: white;
            text-align: center;
            padding: 20px 30px;
            margin-top: 40px;
            border-top: 2px solid #1a1a2e;
        }

        .footer-content {
            max-width: 1400px;
            margin: 0 auto;
            font-size: 0.95em;
        }

        .puzzle-info {
            background: #f0f9ff;
            padding: 12px 16px;
            border-radius: 4px;
            margin-top: 10px;
            font-size: 0.9em;
            color: #1e40af;
        }

        @media (max-width: 1024px) {
            .main-content {
                grid-template-columns: 1fr;
            }
            .tile {
                width: 60px;
                height: 60px;
                font-size: 24px;
            }
            .grid {
                grid-template-columns: repeat(4, 60px);
            }
        }
    </style>
</head>
<body>
    <!-- Navigation Bar -->
    <nav class="navbar">
        <div class="navbar-content">
            <a href="index.html" style="color:white; text-decoration:none; padding:10px 14px; background:rgba(255,255,255,0.06); border-radius:6px; margin-right:14px; font-weight:600;">Home</a>
            <div class="navbar-title">
                <h1>15-Puzzle Reinforcement Learning Simulator</h1>
            </div>
            <div class="navbar-links">
                <a href="#" onclick="openModal('howToModal'); return false;">User Guide</a>
                <a href="#" onclick="openModal('algoModal'); return false;">Algorithms</a>
            </div>
        </div>
    </nav>

    <!-- Modals -->
    <div id="howToModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="close" onclick="closeModal('howToModal')">&times;</span>
                <h2>User Guide</h2>
            </div>
            <div class="modal-body">
                <h3>Puzzle Overview</h3>
                <p>The 15-Puzzle is a classic sliding tile puzzle with 15 numbered tiles in a 4×4 grid with one empty space. The goal is to arrange tiles in order (1-15) by sliding them into the empty space.</p>

                <h3>MDP Formulation</h3>
                <ul>
                    <li><strong>State Space (S):</strong> All valid tile arrangements. Total: 16!/2 ≈ 10.4 trillion states (half are unreachable due to parity)</li>
                    <li><strong>Action Space (A):</strong> 4 directional moves {up, down, left, right} - slide a tile into the empty space</li>
                    <li><strong>Reward Function (R):</strong>
                        <ul style="margin-top: 8px;">
                            <li>+100: Puzzle solved (all tiles in correct position)</li>
                            <li>-Manhattan distance decrease × 2: Reward for getting closer to goal</li>
                            <li>-0.1: Step penalty (encourages shorter solutions)</li>
                        </ul>
                    </li>
                    <li><strong>Transition Dynamics:</strong> Deterministic. Each action slides one adjacent tile into the empty space</li>
                    <li><strong>Solvability:</strong> All scrambled puzzles are solvable (we generate by random valid moves from goal)</li>
                </ul>

                <h3>RL Learning Concepts</h3>
                <ul>
                    <li><strong>Dense rewards:</strong> Manhattan distance provides continuous feedback (unlike Lights Out)</li>
                    <li><strong>Heuristic available:</strong> Manhattan distance = sum of distances each tile is from goal position</li>
                    <li><strong>Branching factor:</strong> 2-4 valid moves per state (better than combinatorial puzzles)</li>
                    <li><strong>Solution length:</strong> Typically 20-80 moves for random scrambles</li>
                    <li><strong>State representation:</strong> 16-element vector (tile positions)</li>
                </ul>

                <h3>Scramble Difficulty</h3>
                <p>Puzzles are generated by applying random moves from the solved state:</p>
                <ul>
                    <li><strong>Easy:</strong> 10 random moves (~10-15 moves to solve)</li>
                    <li><strong>Medium:</strong> 20 random moves (~20-30 moves to solve)</li>
                    <li><strong>Hard:</strong> 50 random moves (~40-60 moves to solve)</li>
                </ul>

                <h3>Training RL Agents</h3>
                <ol>
                    <li>Select scramble difficulty (determines episode complexity)</li>
                    <li>Choose one or more algorithms (Q-Learning, SARSA, Monte Carlo)</li>
                    <li>Configure hyperparameters:
                        <ul>
                            <li>Learning Rate (α): 0.1-0.3 recommended</li>
                            <li>Discount Factor (γ): 0.9-0.95 for medium-term planning</li>
                            <li>Episodes: 1000-5000 (depends on difficulty)</li>
                        </ul>
                    </li>
                    <li>Click "Train Agents" and wait for results</li>
                    <li>View learning curves and performance metrics</li>
                    <li>Simulate learned policies to see solutions</li>
                </ol>

                <h3>What Does Convergence Mean?</h3>
                <p>An algorithm is <strong>converged</strong> when:</p>
                <ul>
                    <li>Successfully solves puzzles consistently (> 70% success rate)</li>
                    <li>Solution length stabilizes and approaches optimal</li>
                    <li>Low variance in performance over last 10 episodes</li>
                </ul>

                <h3>Why 15-Puzzle is Good for RL</h3>
                <ul>
                    <li><strong>Dense rewards:</strong> Manhattan distance provides gradient toward goal</li>
                    <li><strong>Clear progress metric:</strong> Can measure improvement objectively</li>
                    <li><strong>All puzzles solvable:</strong> No wasted training on impossible cases</li>
                    <li><strong>Scalable difficulty:</strong> Control complexity via scramble depth</li>
                    <li><strong>Classic benchmark:</strong> Well-studied in AI literature</li>
                </ul>
            </div>
        </div>
    </div>

    <div id="algoModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="close" onclick="closeModal('algoModal')">&times;</span>
                <h2>Algorithm Information</h2>
            </div>
            <div class="modal-body">
                <div class="algorithm-description">
                    <h3>Q-Learning (Off-Policy TD)</h3>
                    <p><strong>Type:</strong> Off-policy Temporal Difference learning</p>
                    <p><strong>Update Rule:</strong></p>
                    <div class="equation">
                        Q(s,a) ← Q(s,a) + α[r + γ max<sub>a'</sub> Q(s',a') - Q(s,a)]
                    </div>
                    <p><strong>Characteristics:</strong></p>
                    <ul>
                        <li>Learns optimal Q-values independent of behavior policy</li>
                        <li>Uses maximum Q-value of next state (optimistic)</li>
                        <li>Excellent for deterministic environments like 15-Puzzle</li>
                        <li>Can learn from exploratory moves without bias</li>
                    </ul>
                </div>

                <div class="algorithm-description">
                    <h3>SARSA (On-Policy TD)</h3>
                    <p><strong>Type:</strong> On-policy Temporal Difference learning</p>
                    <p><strong>Update Rule:</strong></p>
                    <div class="equation">
                        Q(s,a) ← Q(s,a) + α[r + γ Q(s',a') - Q(s,a)]
                    </div>
                    <p><strong>Characteristics:</strong></p>
                    <ul>
                        <li>Learns value of policy being followed</li>
                        <li>Uses actual next action from ε-greedy policy</li>
                        <li>More conservative updates</li>
                        <li>Considers exploration in its value estimates</li>
                    </ul>
                </div>

                <div class="algorithm-description">
                    <h3>Monte Carlo (First-Visit)</h3>
                    <p><strong>Type:</strong> Episode-based method</p>
                    <p><strong>Update Rule:</strong></p>
                    <div class="equation">
                        Q(s,a) ← Q(s,a) + α[G<sub>t</sub> - Q(s,a)]
                    </div>
                    <p>Where G<sub>t</sub> is the return (sum of discounted rewards) from time t until episode end.</p>
                    <p><strong>Characteristics:</strong></p>
                    <ul>
                        <li>Learns from complete episodes</li>
                        <li>No bootstrapping (uses actual returns)</li>
                        <li>Unbiased but high variance</li>
                        <li>Requires full episode trajectory</li>
                    </ul>
                </div>

                <h3>Comparison: 15-Puzzle vs Gridworld vs Lights Out</h3>
                <table style="width: 100%; border-collapse: collapse; margin-top: 15px;">
                    <tr style="background: #f0f0f0;">
                        <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Aspect</th>
                        <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Gridworld</th>
                        <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">15-Puzzle</th>
                        <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Lights Out</th>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>State Space</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Small (n²)</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Huge (10¹³)</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Exponential (2^n²)</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Reward Signal</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Dense</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Dense (Manhattan)</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Sparse</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Heuristic</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Euclidean dist</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Manhattan dist</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">None obvious</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>RL Difficulty</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Easy</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Medium</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Hard</td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Convergence</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Fast</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Moderate</td>
                        <td style="padding: 10px; border: 1px solid #ddd;">Slow</td>
                    </tr>
                </table>

                <h3>Why 15-Puzzle Works Well</h3>
                <ul>
                    <li><strong>Manhattan Distance:</strong> Provides strong learning signal (reward shaping)</li>
                    <li><strong>All Solvable:</strong> Every generated puzzle has a solution</li>
                    <li><strong>Clear Progress:</strong> Can see agent getting closer to goal</li>
                    <li><strong>Deterministic:</strong> Same moves always produce same result</li>
                </ul>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="main-content">
            <!-- Setup Panel -->
            <div class="panel">
                <h2>Environment Setup</h2>
                
                <div class="control-group">
                    <label for="scrambleDifficulty">Scramble Difficulty</label>
                    <select id="scrambleDifficulty" style="width: 100%; padding: 12px; border: 2px solid #ddd; border-radius: 5px; font-size: 15px;">
                        <option value="10">Easy (10 moves)</option>
                        <option value="20" selected>Medium (20 moves)</option>
                        <option value="50">Hard (50 moves)</option>
                    </select>
                    <button class="secondary" style="margin-top: 10px; width: 100%;" onclick="scramblePuzzle()">New Puzzle</button>
                </div>

                <div class="control-group">
                    <label>Current Puzzle State</label>
                    <div class="grid-container">
                        <div id="grid" class="grid"></div>
                    </div>
                    <div id="puzzleInfo" class="puzzle-info"></div>
                </div>
            </div>

            <!-- Algorithm Panel -->
            <div class="panel">
                <h2>Algorithm Selection</h2>
                
                <div class="control-group">
                    <label>Choose Algorithms to Compare</label>
                    <div class="algorithm-selector">
                        <div class="algorithm-option">
                            <input type="checkbox" id="algoQ" value="qlearning" checked>
                            <label for="algoQ">Q-Learning (Off-Policy TD)</label>
                        </div>
                        <div class="algorithm-option">
                            <input type="checkbox" id="algoSarsa" value="sarsa" checked>
                            <label for="algoSarsa">SARSA (On-Policy TD)</label>
                        </div>
                        <div class="algorithm-option">
                            <input type="checkbox" id="algoMC" value="montecarlo" checked>
                            <label for="algoMC">Monte Carlo (First-Visit)</label>
                        </div>
                    </div>
                </div>

                <div class="control-group">
                    <label>Hyperparameters</label>
                    <div class="hyperparameters">
                        <div class="hyperparam-input">
                            <label for="alpha">Learning Rate (α)</label>
                            <input type="number" id="alpha" min="0" max="1" step="0.01" value="0.2">
                        </div>
                        <div class="hyperparam-input">
                            <label for="gamma">Discount Factor (γ)</label>
                            <input type="number" id="gamma" min="0" max="1" step="0.01" value="0.9">
                        </div>
                        <div class="hyperparam-input">
                            <label for="episodes">Episodes</label>
                            <input type="number" id="episodes" min="100" max="5000" step="100" value="2000">
                        </div>
                    </div>
                    <p style="margin-top: 10px; color: #666; font-size: 0.85em; font-style: italic;">
                        Epsilon decays from 0.3 → 0.05. Q-values initialized optimistically (+10).
                    </p>
                </div>

                <div class="button-group">
                    <button class="primary" onclick="trainAlgorithms()">Train Agents</button>
                    <button class="secondary" onclick="resetEnvironment()">Reset All</button>
                </div>
                
                <div class="button-group" style="margin-top: 15px;">
                    <button class="simulate-btn" onclick="simulateBestPath()">Simulate Learned Policy</button>
                </div>
            </div>

            <!-- Results Panel -->
            <div class="panel results-panel">
                <h2>Training Results</h2>
                <div id="loadingMessage" class="loading" style="display: none;">
                    Training in progress...
                </div>
                <canvas id="resultsChart"></canvas>
                <div id="stats" class="stats"></div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="footer-content">
            <span><strong>CS329</strong> Foundations of AI - 15-Puzzle RL Project</span>
        </div>
    </footer>

    <script>
        // ====== GLOBAL STATE ======
        let tiles = [];
        let initialTiles = [];
        let emptyPos = { row: 3, col: 3 };
        let trainingResults = {};
        const GRID_SIZE = 4;

        // ====== PUZZLE HELPERS ======
        function createSolvedPuzzle() {
            tiles = [];
            for (let i = 0; i < GRID_SIZE; i++) {
                tiles[i] = [];
                for (let j = 0; j < GRID_SIZE; j++) {
                    tiles[i][j] = i * GRID_SIZE + j + 1;
                }
            }
            tiles[GRID_SIZE - 1][GRID_SIZE - 1] = 0; // Empty tile
            emptyPos = { row: GRID_SIZE - 1, col: GRID_SIZE - 1 };
        }

        function renderGrid() {
            const gridElement = document.getElementById('grid');
            gridElement.innerHTML = '';
            
            for (let i = 0; i < GRID_SIZE; i++) {
                for (let j = 0; j < GRID_SIZE; j++) {
                    const tile = document.createElement('div');
                    const value = tiles[i][j];
                    
                    if (value === 0) {
                        tile.className = 'tile empty';
                    } else {
                        tile.className = 'tile';
                        tile.textContent = value;
                    }
                    
                    gridElement.appendChild(tile);
                }
            }
        }

        function canMove(direction) {
            const { row, col } = emptyPos;
            switch(direction) {
                case 0: return row > 0; // up
                case 1: return row < GRID_SIZE - 1; // down
                case 2: return col > 0; // left
                case 3: return col < GRID_SIZE - 1; // right
                default: return false;
            }
        }

        function applyMove(direction) {
            if (!canMove(direction)) return false;
            
            const { row, col } = emptyPos;
            let newRow = row, newCol = col;
            
            switch(direction) {
                case 0: newRow--; break; // up
                case 1: newRow++; break; // down
                case 2: newCol--; break; // left
                case 3: newCol++; break; // right
            }
            
            // Swap
            tiles[row][col] = tiles[newRow][newCol];
            tiles[newRow][newCol] = 0;
            emptyPos = { row: newRow, col: newCol };
            
            return true;
        }

        function scramblePuzzle() {
            createSolvedPuzzle();
            const moves = parseInt(document.getElementById('scrambleDifficulty').value);
            
            let lastMove = -1;
            for (let i = 0; i < moves; i++) {
                const validMoves = [];
                for (let dir = 0; dir < 4; dir++) {
                    // Avoid undoing the last move
                    if (canMove(dir) && dir !== (lastMove ^ 1)) {
                        validMoves.push(dir);
                    }
                }
                
                if (validMoves.length > 0) {
                    const move = validMoves[Math.floor(Math.random() * validMoves.length)];
                    applyMove(move);
                    lastMove = move;
                }
            }
            
            initialTiles = tiles.map(row => [...row]);
            renderGrid();
            updatePuzzleInfo();
        }

        function manhattanDistance(state) {
            let dist = 0;
            for (let i = 0; i < GRID_SIZE; i++) {
                for (let j = 0; j < GRID_SIZE; j++) {
                    const value = state[i][j];
                    if (value !== 0) {
                        const targetRow = Math.floor((value - 1) / GRID_SIZE);
                        const targetCol = (value - 1) % GRID_SIZE;
                        dist += Math.abs(i - targetRow) + Math.abs(j - targetCol);
                    }
                }
            }
            return dist;
        }

        function isSolved(state) {
            for (let i = 0; i < GRID_SIZE; i++) {
                for (let j = 0; j < GRID_SIZE; j++) {
                    const expected = i * GRID_SIZE + j + 1;
                    if (i === GRID_SIZE - 1 && j === GRID_SIZE - 1) {
                        if (state[i][j] !== 0) return false;
                    } else {
                        if (state[i][j] !== expected) return false;
                    }
                }
            }
            return true;
        }

        function stateToString(state) {
            return state.flat().join(',');
        }

        function updatePuzzleInfo() {
            const dist = manhattanDistance(initialTiles);
            document.getElementById('puzzleInfo').innerHTML = 
                `<strong>Manhattan Distance:</strong> ${dist} (estimated minimum moves)`;
        }

        // ====== RL ENVIRONMENT ======
        class PuzzleEnvironment {
            constructor(initialState) {
                this.initialState = initialState.map(row => [...row]);
                this.reset();
            }

            reset() {
                this.state = this.initialState.map(row => [...row]);
                // Find empty position
                for (let i = 0; i < GRID_SIZE; i++) {
                    for (let j = 0; j < GRID_SIZE; j++) {
                        if (this.state[i][j] === 0) {
                            this.emptyPos = { row: i, col: j };
                            return this.state;
                        }
                    }
                }
                return this.state;
            }

            canMove(direction) {
                const { row, col } = this.emptyPos;
                switch(direction) {
                    case 0: return row > 0;
                    case 1: return row < GRID_SIZE - 1;
                    case 2: return col > 0;
                    case 3: return col < GRID_SIZE - 1;
                    default: return false;
                }
            }

            step(action) {
                if (!this.canMove(action)) {
                    return { nextState: this.state, reward: -5, done: false };
                }

                const prevDist = manhattanDistance(this.state);
                
                const { row, col } = this.emptyPos;
                let newRow = row, newCol = col;
                
                switch(action) {
                    case 0: newRow--; break;
                    case 1: newRow++; break;
                    case 2: newCol--; break;
                    case 3: newCol++; break;
                }
                
                this.state[row][col] = this.state[newRow][newCol];
                this.state[newRow][newCol] = 0;
                this.emptyPos = { row: newRow, col: newCol };
                
                const currDist = manhattanDistance(this.state);
                const done = isSolved(this.state);
                
                let reward;
                if (done) {
                    reward = 100;
                } else {
                    const progress = prevDist - currDist;
                    reward = progress * 2 - 0.1;
                }
                
                return { nextState: this.state, reward, done };
            }
        }

        // ====== RL UTILITIES ======
        function initQ() {
            return {};
        }

        function getQValues(Q, stateStr, optimisticInit = 0) {
            if (!(stateStr in Q)) {
                Q[stateStr] = Array(4).fill(optimisticInit);
            }
            return Q[stateStr];
        }

        function epsGreedy(Q, state, epsilon, env) {
            const stateStr = stateToString(state);
            
            if (Math.random() < epsilon) {
                // Random valid action
                const validActions = [];
                for (let a = 0; a < 4; a++) {
                    if (env.canMove(a)) validActions.push(a);
                }
                return validActions[Math.floor(Math.random() * validActions.length)];
            }
            
            const qValues = getQValues(Q, stateStr, 10);
            // Choose best valid action
            let bestAction = -1;
            let bestValue = -Infinity;
            for (let a = 0; a < 4; a++) {
                if (env.canMove(a) && qValues[a] > bestValue) {
                    bestValue = qValues[a];
                    bestAction = a;
                }
            }
            return bestAction;
        }

        // ====== Q-LEARNING ======
        function qLearning(env, alpha, gamma, epsilon, episodes) {
            const Q = initQ();
            const stepsPerEpisode = [];
            const successPerEpisode = [];
            const optimisticInit = 10;
            
            for (let ep = 0; ep < episodes; ep++) {
                const currentEpsilon = Math.max(0.05, epsilon * (1 - ep / episodes));
                
                let state = env.reset();
                let done = false;
                let steps = 0;
                const maxSteps = 200;
                
                while (!done && steps < maxSteps) {
                    const stateStr = stateToString(state);
                    const action = epsGreedy(Q, state, currentEpsilon, env);
                    
                    const { nextState, reward, done: isDone } = env.step(action);
                    done = isDone;
                    
                    const nextStateStr = stateToString(nextState);
                    const qNext = getQValues(Q, nextStateStr, optimisticInit);
                    const maxQNext = Math.max(...qNext);
                    
                    const qCurr = getQValues(Q, stateStr, optimisticInit);
                    qCurr[action] += alpha * (reward + gamma * maxQNext - qCurr[action]);
                    
                    state = nextState;
                    steps++;
                }
                
                stepsPerEpisode.push(steps);
                successPerEpisode.push(done ? 1 : 0);
            }
            
            return { Q, stepsPerEpisode, successPerEpisode };
        }

        // ====== SARSA ======
        function sarsa(env, alpha, gamma, epsilon, episodes) {
            const Q = initQ();
            const stepsPerEpisode = [];
            const successPerEpisode = [];
            const optimisticInit = 10;
            
            for (let ep = 0; ep < episodes; ep++) {
                const currentEpsilon = Math.max(0.05, epsilon * (1 - ep / episodes));
                
                let state = env.reset();
                let stateStr = stateToString(state);
                let action = epsGreedy(Q, state, currentEpsilon, env);
                let done = false;
                let steps = 0;
                const maxSteps = 200;
                
                while (!done && steps < maxSteps) {
                    const { nextState, reward, done: isDone } = env.step(action);
                    done = isDone;
                    
                    const nextStateStr = stateToString(nextState);
                    const nextAction = epsGreedy(Q, nextState, currentEpsilon, env);
                    
                    const qCurr = getQValues(Q, stateStr, optimisticInit);
                    const qNext = getQValues(Q, nextStateStr, optimisticInit);
                    qCurr[action] += alpha * (reward + gamma * qNext[nextAction] - qCurr[action]);
                    
                    state = nextState;
                    stateStr = nextStateStr;
                    action = nextAction;
                    steps++;
                }
                
                stepsPerEpisode.push(steps);
                successPerEpisode.push(done ? 1 : 0);
            }
            
            return { Q, stepsPerEpisode, successPerEpisode };
        }

        // ====== MONTE CARLO ======
        function monteCarlo(env, alpha, gamma, epsilon, episodes) {
            const Q = initQ();
            const stepsPerEpisode = [];
            const successPerEpisode = [];
            const optimisticInit = 10;
            
            for (let ep = 0; ep < episodes; ep++) {
                const currentEpsilon = Math.max(0.05, epsilon * (1 - ep / episodes));
                
                let state = env.reset();
                const episode = [];
                let done = false;
                let steps = 0;
                const maxSteps = 200;
                
                while (!done && steps < maxSteps) {
                    const stateStr = stateToString(state);
                    const action = epsGreedy(Q, state, currentEpsilon, env);
                    const { nextState, reward, done: isDone } = env.step(action);
                    
                    episode.push({ state: stateStr, action, reward });
                    state = nextState;
                    done = isDone;
                    steps++;
                }
                
                stepsPerEpisode.push(steps);
                successPerEpisode.push(done ? 1 : 0);
                
                let G = 0;
                const visited = new Set();
                
                for (let t = episode.length - 1; t >= 0; t--) {
                    const { state: s, action: a, reward: r } = episode[t];
                    G = gamma * G + r;
                    
                    const saKey = `${s},${a}`;
                    if (!visited.has(saKey)) {
                        visited.add(saKey);
                        const qValues = getQValues(Q, s, optimisticInit);
                        qValues[a] += alpha * (G - qValues[a]);
                    }
                }
            }
            
            return { Q, stepsPerEpisode, successPerEpisode };
        }

        // ====== TRAINING ======
        async function trainAlgorithms() {
            const selectedAlgorithms = [];
            if (document.getElementById('algoQ').checked) selectedAlgorithms.push('qlearning');
            if (document.getElementById('algoSarsa').checked) selectedAlgorithms.push('sarsa');
            if (document.getElementById('algoMC').checked) selectedAlgorithms.push('montecarlo');
            
            if (selectedAlgorithms.length === 0) {
                alert('Please select at least one algorithm!');
                return;
            }
            
            const alpha = parseFloat(document.getElementById('alpha').value);
            const gamma = parseFloat(document.getElementById('gamma').value);
            const epsilon = 0.3;
            const episodes = parseInt(document.getElementById('episodes').value);
            
            if (alpha <= 0 || alpha >= 1) {
                alert('Learning Rate (α) must be between 0 and 1 (exclusive).');
                return;
            }
            if (gamma < 0 || gamma >= 1) {
                alert('Discount Factor (γ) must be between 0 and 1 (exclusive for 1).');
                return;
            }
            
            document.getElementById('loadingMessage').style.display = 'block';
            document.getElementById('stats').innerHTML = '';
            
            trainingResults = {};
            
            const env = new PuzzleEnvironment(initialTiles);
            
            await new Promise(resolve => setTimeout(resolve, 100));
            
            for (const algo of selectedAlgorithms) {
                let result;
                
                switch (algo) {
                    case 'qlearning':
                        result = qLearning(env, alpha, gamma, epsilon, episodes);
                        trainingResults['Q-Learning'] = result;
                        break;
                    case 'sarsa':
                        result = sarsa(env, alpha, gamma, epsilon, episodes);
                        trainingResults['SARSA'] = result;
                        break;
                    case 'montecarlo':
                        result = monteCarlo(env, alpha, gamma, epsilon, episodes);
                        trainingResults['Monte Carlo'] = result;
                        break;
                }
            }
            
            document.getElementById('loadingMessage').style.display = 'none';
            displayResults();
        }

        // ====== VISUALIZATION ======
        function displayResults() {
            const canvas = document.getElementById('resultsChart');
            const ctx = canvas.getContext('2d');
            
            canvas.width = canvas.offsetWidth;
            canvas.height = 400;
            
            const width = canvas.width;
            const height = canvas.height;
            const padding = 60;
            
            ctx.clearRect(0, 0, width, height);
            
            let maxEpisodes = 0;
            let maxSteps = 0;
            
            for (const [name, data] of Object.entries(trainingResults)) {
                maxEpisodes = Math.max(maxEpisodes, data.stepsPerEpisode.length);
                maxSteps = Math.max(maxSteps, ...data.stepsPerEpisode);
            }
            
            ctx.strokeStyle = '#333';
            ctx.lineWidth = 2;
            ctx.beginPath();
            ctx.moveTo(padding, padding);
            ctx.lineTo(padding, height - padding);
            ctx.lineTo(width - padding, height - padding);
            ctx.stroke();
            
            ctx.fillStyle = '#333';
            ctx.font = '14px Arial';
            ctx.textAlign = 'center';
            ctx.fillText('Episodes', width / 2, height - 20);
            
            ctx.save();
            ctx.translate(20, height / 2);
            ctx.rotate(-Math.PI / 2);
            ctx.fillText('Steps per Episode', 0, 0);
            ctx.restore();
            
            ctx.strokeStyle = '#e5e7eb';
            ctx.lineWidth = 1;
            for (let i = 0; i <= 5; i++) {
                const y = padding + (height - 2 * padding) * i / 5;
                ctx.beginPath();
                ctx.moveTo(padding, y);
                ctx.lineTo(width - padding, y);
                ctx.stroke();
                
                ctx.fillStyle = '#666';
                ctx.font = '12px Arial';
                ctx.textAlign = 'right';
                const value = Math.round(maxSteps * (1 - i / 5));
                ctx.fillText(value.toString(), padding - 10, y + 4);
            }
            
            const colors = {
                'Q-Learning': '#3b82f6',
                'SARSA': '#10b981',
                'Monte Carlo': '#f59e0b'
            };
            
            for (const [name, data] of Object.entries(trainingResults)) {
                ctx.strokeStyle = colors[name];
                ctx.lineWidth = 2;
                ctx.beginPath();
                
                const steps = data.stepsPerEpisode;
                for (let i = 0; i < steps.length; i++) {
                    const x = padding + (width - 2 * padding) * i / maxEpisodes;
                    const y = height - padding - (height - 2 * padding) * steps[i] / maxSteps;
                    
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                }
                ctx.stroke();
            }
            
            let legendY = padding + 20;
            for (const [name, data] of Object.entries(trainingResults)) {
                ctx.fillStyle = colors[name];
                ctx.fillRect(width - padding - 150, legendY - 8, 20, 3);
                ctx.fillStyle = '#333';
                ctx.font = '14px Arial';
                ctx.textAlign = 'left';
                ctx.fillText(name, width - padding - 125, legendY);
                legendY += 25;
            }
            
            displayStats();
        }

        function displayStats() {
            const statsDiv = document.getElementById('stats');
            statsDiv.innerHTML = '';
            
            for (const [name, data] of Object.entries(trainingResults)) {
                const successRate = (data.successPerEpisode.reduce((a, b) => a + b, 0) / data.successPerEpisode.length * 100).toFixed(1);
                const avgSteps = (data.stepsPerEpisode.reduce((a, b) => a + b, 0) / data.stepsPerEpisode.length).toFixed(1);
                
                // Find convergence episode (first episode where success rate over next 100 episodes > 70%)
                let convergenceEpisode = null;
                const windowSize = 100;
                for (let i = 0; i <= data.successPerEpisode.length - windowSize; i++) {
                    const windowSuccess = data.successPerEpisode.slice(i, i + windowSize);
                    const windowRate = (windowSuccess.reduce((a, b) => a + b, 0) / windowSize) * 100;
                    if (windowRate > 70) {
                        convergenceEpisode = i + 1;
                        break;
                    }
                }
                
                const card = document.createElement('div');
                card.className = 'stat-card';
                
                const converged = parseFloat(successRate) > 70;
                let convergenceText;
                if (converged && convergenceEpisode) {
                    convergenceText = `<p style="color: #10b981; margin-top: 8px; font-size: 0.9em; font-weight: 600;">✓ Converged at Episode ${convergenceEpisode} (${successRate}% success)</p>`;
                } else if (converged) {
                    convergenceText = `<p style="color: #10b981; margin-top: 8px; font-size: 0.9em; font-weight: 600;">✓ Converged (${successRate}% success)</p>`;
                } else {
                    convergenceText = `<p style="color: #ef4444; margin-top: 8px; font-size: 0.9em; font-weight: 600;">✗ Did not converge (${successRate}% success)</p>`;
                }
                
                card.innerHTML = `
                    <h3>${name}</h3>
                    <div class="value">${avgSteps}</div>
                    <p style="color: #666; margin-top: 8px;">Average Steps per Episode</p>
                    ${convergenceText}
                `;
                statsDiv.appendChild(card);
            }
        }

        function simulateBestPath() {
            if (Object.keys(trainingResults).length === 0) {
                alert('Please train algorithms first!');
                return;
            }
            
            let bestAlgo = null;
            let bestSuccess = 0;
            
            for (const [name, data] of Object.entries(trainingResults)) {
                const successRate = data.successPerEpisode.reduce((a, b) => a + b, 0) / data.successPerEpisode.length;
                if (successRate > bestSuccess) {
                    bestSuccess = successRate;
                    bestAlgo = { name, Q: data.Q };
                }
            }
            
            if (!bestAlgo || bestSuccess < 0.1) {
                alert('No algorithm has learned a successful policy. Try:\n- More episodes\n- Different hyperparameters\n- Easier scramble difficulty');
                return;
            }
            
            const env = new PuzzleEnvironment(initialTiles);
            let state = env.reset();
            const maxSteps = 200;
            let steps = 0;
            let done = false;
            
            tiles = state.map(row => [...row]);
            for (let i = 0; i < GRID_SIZE; i++) {
                for (let j = 0; j < GRID_SIZE; j++) {
                    if (tiles[i][j] === 0) {
                        emptyPos = { row: i, col: j };
                    }
                }
            }
            renderGrid();
            
            const interval = setInterval(() => {
                if (done || steps >= maxSteps) {
                    clearInterval(interval);
                    if (done) {
                        alert(`${bestAlgo.name} solved in ${steps} steps!`);
                    } else {
                        alert(`${bestAlgo.name} failed to solve within ${maxSteps} steps.`);
                    }
                    return;
                }
                
                const stateStr = stateToString(state);
                const qValues = getQValues(bestAlgo.Q, stateStr, 10);
                
                let bestAction = -1;
                let bestValue = -Infinity;
                for (let a = 0; a < 4; a++) {
                    if (env.canMove(a) && qValues[a] > bestValue) {
                        bestValue = qValues[a];
                        bestAction = a;
                    }
                }
                
                const { nextState, reward, done: isDone } = env.step(bestAction);
                state = nextState;
                done = isDone;
                steps++;
                
                tiles = state.map(row => [...row]);
                for (let i = 0; i < GRID_SIZE; i++) {
                    for (let j = 0; j < GRID_SIZE; j++) {
                        if (tiles[i][j] === 0) {
                            emptyPos = { row: i, col: j };
                        }
                    }
                }
                renderGrid();
            }, 400);
        }

        function resetEnvironment() {
            trainingResults = {};
            document.getElementById('resultsChart').getContext('2d').clearRect(0, 0, 1000, 400);
            document.getElementById('stats').innerHTML = '';
            scramblePuzzle();
        }

        function openModal(modalId) {
            document.getElementById(modalId).style.display = 'block';
        }

        function closeModal(modalId) {
            document.getElementById(modalId).style.display = 'none';
        }

        window.onclick = function(event) {
            if (event.target.classList.contains('modal')) {
                event.target.style.display = 'none';
            }
        }

        // Initialize
        scramblePuzzle();
    </script>
</body>
</html>
